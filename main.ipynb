import requests
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
import requests
from bs4 import BeautifulSoup
import json
import os

for i in range(len(dlist)):
    # Extract the values of MESH ID, disease name, OMIM ID, DisGeNET Disease ID, Harmonizome Query Term
    # from the dlist and assign them to corresponding variables
    i = i+22
    MESH_ID = dlist["MESH ID"][i]
    Disease_Name = dlist["diseaseName"][i]
    OMIM_ID = dlist["OMIM"][i]
    Disgenet_Disease_ID = dlist["DisGeNETDiseaseId"][i]
    harmonizome_queryterm = dlist["HarmonizomeQueryTerm"][i]

    # Replace the spaces in the Harmonizome query term with '+' and the apostrophes with '%27'
    # and convert the string to lowercase
    harmonizome_decease_name = harmonizome_queryterm.replace(' ', '+')
    harmonizome_decease_name = harmonizome_decease_name.replace("'", "%27")
    harmonizome_decease_name = harmonizome_decease_name.lower()

    # Create BIONDA and Pubpular filenames by replacing the spaces in the disease name with '_'
    BIONDA_filename = Disease_Name + " BIONDA"
    Pubpular_filename = Disease_Name + " Pubpular"

    # Create a master folder path and create the folder if it does not already exist
    master_folder_path = f"./Master Folder 2/{Disease_Name}_{MESH_ID}"
    if not os.path.exists(master_folder_path):
        os.makedirs(master_folder_path)

    # Construct the CTD URL using MESH ID and disease name, and create a CTD filename
    
    ctd_url = f"https://ctdbase.org/detail.go;jsessionid=385F14EFFD796AF9E5182714E9B94C73;jsessionid=35B21D1728528E4FF50BA934E3598789?acc=MESH%3A{MESH_ID}&view=gene&6578706f7274=1&type=disease&d-1332398-e=1"
    ctd_filename = f"CTD_{Disease_Name}_{MESH_ID}_Only_reading.csv"

    if os.path.isfile(ctd_filename):
        print(f"File '{ctd_filename}' already exists in the directory. Skipping download.")
    else:
        print(f"File '{ctd_filename}' does not exist in the directory. Downloading...")
        # Download the CTD data from the URL and write it to a file
        response = requests.get(ctd_url)
        if response.status_code == 200:
            with open(ctd_filename, "wb") as f:
                f.write(response.content)
            print(f"Successfully downloaded CTD data for {Disease_Name}")
        else:
            # If download is not successful, save an empty file and print a message
            print(f"Download failed for CTD data for {Disease_Name}. Saving an empty file.")
            with open(ctd_filename, "w") as f:
                f.write("")
            
    

    # Read the CTD data from the file and drop the 'Inference Network' column
    df = pd.read_csv(ctd_filename)

    if not df.empty:
        df.drop(['Inference Network'], axis=1, inplace=True)

        # Replace missing values in the 'Inference Score' column with '#N/A'
        df['Inference Score'].fillna(value="#N/A", inplace=True)

        # Merge the CTD and ndf dataframes on 'Gene ID' and 'NCBI GeneID' columns, respectively,
        # to get the common rows and extract the rows that have the disease ID same as MESH ID
        common_rows = pd.merge(df, ndf, left_on='Gene ID', right_on='NCBI GeneID', how='inner')
        ncdf = common_rows[common_rows["Disease ID"] == f"MESH:{MESH_ID}"]

        # Create a new column 'CTD_Marker' by applying a lambda function that assigns 1 to rows
        # that have 'therapeutic' or 'marker/mechanism' in the 'Direct Evidence' column, 0 to rows
        # that have NaN values in that column, and None to rows that have other values
        ncdf['CTD_Marker'] = ncdf['Direct Evidence'].apply(lambda x: 1 if x in ['therapeutic', 'marker/mechanism'] else 0 if pd.isna(x) else None)
        # Checking if 'Inference Score' column in 'ncdf' dataframe is numeric
        if not pd.api.types.is_numeric_dtype(ncdf['Inference Score']):
            # Converting the column to numeric type with errors coerced to NaN
            ncdf['Inference Score'] = pd.to_numeric(ncdf['Inference Score'], errors='coerce')

        # Taking the log base 10 of the 'Inference Score' column and storing it in a new 'Mod_CTD' column
        ncdf['Mod_CTD'] = np.log10(ncdf['Inference Score'])

        # Scaling 'Mod_CTD' column using MinMaxScaler
        scaler = MinMaxScaler()
        ncdf["Mod_CTD"] = scaler.fit_transform(ncdf[["Mod_CTD"]])

        # Creating a new dataframe with selected columns from 'ncdf'
        ctd_download = ncdf[['Gene Symbol', 'Gene ID', 'Disease Name', 'Disease ID',
                'Direct Evidence', 'Inference Score', 'Reference Count','Mod_CTD','CTD_Marker']]

        # Creating a filepath to save the downloaded CTD data in a csv file
        ctd_file_path = os.path.join(master_folder_path, f"CTD_{Disease_Name}_{MESH_ID}.csv")

        # Saving the 'ctd_download' dataframe as a csv file in the specified filepath
        ctd_download.to_csv(ctd_file_path, index=False)

        # Printing a success message indicating that CTD data has been downloaded
        print(f"Successfully Downloaded CTD Data for {Disease_Name}")
    else:
        empty_df = pd.DataFrame()
        ctd_file_path = os.path.join(master_folder_path, f"CTD_{Disease_Name}_{MESH_ID}.csv")
        empty_df.to_csv(ctd_file_path, index=False)
        print(f"The CTD data for {Disease_Name} is empty. An empty CSV file has been saved.")


    # Creating a URL using OMIM_ID and scraping data from the website
    Edager_URL = f"http://edgar.biocomp.unibo.it/gene_disease_db/disease_static/{OMIM_ID}_static.html"
    try:
        # Sending a GET request to the URL and parsing the HTML content using BeautifulSoup
        response = requests.get(Edager_URL)
        soup = BeautifulSoup(response.content, 'html.parser')

        # Finding the HTML table with id 'main_table'
        gene_table = soup.find('table', {'id': 'main_table'})

        # Extracting all table rows except the first one as it contains header information
        edager_gene_rows = gene_table.find_all('tr')[1:]

        # Extracting gene names from each row and storing them in a list 'edager_gene_names'
        edager_gene_names = []
        for row in edager_gene_rows:
            gene_name = row.find('td').text
            edager_gene_names.append(gene_name)

    # Skipping the code if any URL error occurs
    except (requests.exceptions.RequestException, AttributeError):
        pass

    harmonizome_URL = f"https://maayanlab.cloud/Harmonizome/api/1.0/gene_set/{harmonizome_decease_name}/DISEASES+Text-mining+Gene-Disease+Assocation+Evidence+Scores"

    try:
        response_API = requests.get(harmonizome_URL)
        data = response_API.text
        parse_json = json.loads(data)

        Hz=[]
        for ele in parse_json['associations']:
            temp={}
            temp['Har_Gene']=ele['gene']['symbol']
            temp['standardizedValue']=ele["standardizedValue"]
            Hz.append(temp)

        df = pd.DataFrame(Hz)

    except:
        # If there's an error, create an empty dataframe
        df = pd.DataFrame()

    
    if not df.empty:
        # copy the data
        df_sklearn = df.copy()
        
        # apply normalization techniques
        column = 'standardizedValue'
        df_sklearn["Mod_Standard_Value"] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))
        
        # view normalized data  
        harmonizome_file_path = os.path.join(master_folder_path, f"Harmonizome_{Disease_Name}_{MESH_ID}.csv")
        df_sklearn.to_csv(harmonizome_file_path, index=False)
        print(f"Successfully Downloaded Harmonizome Data for {Disease_Name}")
    else:
        # If the dataframe is empty, create an empty dataframe and print a message
        df_sklearn = pd.DataFrame()
        harmonizome_file_path = os.path.join(master_folder_path, f"Harmonizome_{Disease_Name}_{MESH_ID}.csv")
        df_sklearn.to_csv(harmonizome_file_path, index=False)
        print(f"Harmonizome Data for {Disease_Name} is empty. Saving as an empty dataframe.")


    the_data = {"email": "200040114@iitb.ac.in", "password": "Godayadav28"}
    headers = {'Content-Type': 'application/x-www-form-urlencoded'}
    # Execute the post
    response_API3 = requests.post('https://www.disgenet.org/api/auth/', data=the_data, headers=headers)
    data3=response_API3.text
    parse_json3 = json.loads(data3)
    parse_json3
    soo=requests.Session()

    soo.headers.update({"Authorization": "Bearer 3e807426707eabc1ad1988efc6085870b13fd97c"})

    Disgenet_URL = f"https://www.disgenet.org/api/gda/disease/{Disgenet_Disease_ID}"
    response_API2 = soo.get(Disgenet_URL)

    data2=response_API2.text
    parse_json2 = json.loads(data2)
    data_new=[]
    #Gene_id”, "Gene",”Uniprot”, "Score_gda", "DPI_g", "EI_gda"

    for ele in parse_json2:
        temp={}
        temp["geneid"] = ele["geneid"]
        temp["gene_symbol"] = ele["gene_symbol"]
        temp["uniprotid"] = ele["uniprotid"]
        temp["score"] = ele["score"]
        temp["gene_dpi"] = ele["gene_dpi"]
        temp["ei"] = ele["ei"]
        data_new.append(temp)
    
    import pandas as pd
    df = pd.DataFrame(data_new)
    df['ei'] = df['ei'].fillna(0)
    df["score_norm"] = df[["score"]]
    df["gene_dpi_norm"] = df[["gene_dpi"]]
    df["ei_norm"] = df[["ei"]]

    # Calculate the mean of the normalized columns
    mean_norm = (df["score_norm"] + df["gene_dpi_norm"] + df["ei_norm"]) / 3

    # Add the normalized mean as a new column
    df["DISGENET_Score"] = mean_norm    
    
    from sklearn.preprocessing import MinMaxScaler
    import numpy as np
    
    # copy the data
    Disgenet = df.copy()
    
    column = 'DISGENET_Score'

    scaler = MinMaxScaler()
    df["score_norm"] = scaler.fit_transform(df[["score"]])
    df["gene_dpi_norm"] = scaler.fit_transform(df[["gene_dpi"]])
    df["ei_norm"] = scaler.fit_transform(df[["ei"]])

    MOD_mean_norm = (df["score_norm"] + df["gene_dpi_norm"] + df["ei_norm"]) / 3


    Disgenet["MOD_DISGENET_Score"] = MOD_mean_norm
    Disgenet["MOD_DISGENET_Score"] = scaler.fit_transform(Disgenet[["MOD_DISGENET_Score"]])
    Disgenet_file_path = os.path.join(master_folder_path, f"DISGenet_{Disease_Name}_{MESH_ID}.csv")
    Disgenet.to_csv(Disgenet_file_path, index=False)
    print(f"Successfully Downloaded DISGenet Data for {Disease_Name}")

    

    # Download the file for each disease and upload it to the local device
    Pubpular = pd.read_csv(f"D:\\OneDrive - Indian Institute of Technology Bombay\\Desktop\\3rd Year 2nd Semester\\DH 307\\22nd March\\1.BIONDA and PubPular Files\\{Disease_Name}\\{Pubpular_filename}.csv")

    Pubpular_df = Pubpular[["WCD"]] 
    Pubpular_arr = Pubpular_df.to_numpy()

    scaler = MinMaxScaler()
    scaler.fit(Pubpular_arr)
    Pubpular_array = scaler.transform(Pubpular_arr)

    Pubpular_Norm_WCD = (1-Pubpular_array)

    Pubpular_WCD = pd.DataFrame(Pubpular_array, columns = ['Norm_WCD'])
    Pubpular_Final_WCD = pd.DataFrame(Pubpular_Norm_WCD, columns = ['Mod_Pubpular'])

    Pubpular_Consolidate = pd.concat([Pubpular, Pubpular_WCD, Pubpular_Final_WCD], axis=1)
    Pubpular_Final = Pubpular_Consolidate.fillna(0) # Fill NAN with 0

    Pubpular_file_path = os.path.join(master_folder_path, f"Pubpular_{Disease_Name}_{MESH_ID}.csv")
    Pubpular_Final.to_csv(Pubpular_file_path, index=False)
    print(f"Successfully Downloaded Pubpular Data for {Disease_Name}")



    # Reads three CSV files using Pandas
    ctd_df = pd.read_csv(f"D:\\OneDrive - Indian Institute of Technology Bombay\\Desktop\\3rd Year 2nd Semester\\DH 307\\22nd March\\Master Folder 2\\{Disease_Name}_{MESH_ID}\\CTD_{Disease_Name}_{MESH_ID}.csv") 
    
    pubpular_df = pd.read_csv(f"D:\\OneDrive - Indian Institute of Technology Bombay\\Desktop\\3rd Year 2nd Semester\\DH 307\\22nd March\\Master Folder 2\\{Disease_Name}_{MESH_ID}\\Pubpular_{Disease_Name}_{MESH_ID}.csv") 
    try:
        harmonizome_df = pd.read_csv(f"D:\\OneDrive - Indian Institute of Technology Bombay\\Desktop\\3rd Year 2nd Semester\\DH 307\\22nd March\\Master Folder 2\\{Disease_Name}_{MESH_ID}\\Harmonizome_{Disease_Name}_{MESH_ID}.csv")
    
    except: 
        harmonizome_df = pd.DataFrame(columns=['Har_Gene', 'standardizedValue', 'Mod_Standard_Value'])


    disgenet_df = pd.read_csv(f"D:\\OneDrive - Indian Institute of Technology Bombay\\Desktop\\3rd Year 2nd Semester\\DH 307\\22nd March\\Master Folder 2\\{Disease_Name}_{MESH_ID}\\DISGenet_{Disease_Name}_{MESH_ID}.csv")

    intermediate_df = pd.merge(ndf, ctd_df, how='outer', left_on='NCBI GeneID', right_on='Gene ID')

    intermediate_df = pd.merge(intermediate_df, harmonizome_df, how='outer', left_on='Gene Name', right_on='Har_Gene')

    intermediate_df = pd.merge(intermediate_df, pubpular_df, how='outer', left_on='Gene Name', right_on='GN')

    intermediate_df = pd.merge(intermediate_df, disgenet_df, how='outer', left_on='NCBI GeneID', right_on='geneid')




    # Selects a subset of columns from the intermediate dataframe
    intermediate_df = intermediate_df[['NCBI GeneID', 'Ensembl GeneIDs', 'OMIM IDs', 'SwissProt Accessions', 'Gene Name','DISGENET_Score', 'MOD_DISGENET_Score','standardizedValue','Mod_Standard_Value','Mod_Pubpular','WCD','Norm_WCD','Mod_CTD','CTD_Marker','Inference Score']]

    # Selects a subset of columns to use for further processing
    score_cols = ['MOD_DISGENET_Score', 'Mod_Standard_Value', 'Mod_Pubpular', 'Mod_CTD']

    # Drops any rows from the intermediate dataframe where at least two of the score columns have NaN values
    intermediate_df = intermediate_df.dropna(subset=score_cols, thresh=2)

    # Adds a new column to the intermediate dataframe based on whether each gene name is in a list called "edager_gene_names"
    intermediate_df["Edager_Marker"] = intermediate_df["Gene Name"].apply(lambda x: 1 if x in edager_gene_names else 0)


    # check if the BIONDA file exists, if yes, extract required columns and create a new column "BIONDA_Marker" in the intermediate dataframe
    # else, set "BIONDA_Marker" to "#N/A"
    if os.path.exists(f"D:\\OneDrive - Indian Institute of Technology Bombay\\Desktop\\3rd Year 2nd Semester\\DH 307\\22nd March\\1.BIONDA and PubPular Files\\{Disease_Name}\\{BIONDA_filename}.csv"):
        df = pd.read_csv(f"D:\\OneDrive - Indian Institute of Technology Bombay\\Desktop\\3rd Year 2nd Semester\\DH 307\\22nd March\\1.BIONDA and PubPular Files\\{Disease_Name}\\{BIONDA_filename}.csv")
        bionda_columns = ["Marker", "Gene", "To"]
        bionda_values = []
        for col in bionda_columns:
            # check if the column exists in the BIONDA file and add the column values to a list
            if col in df.columns:
                bionda_values += df[col].fillna('').tolist()
        # create a new column "BIONDA_Marker" in the intermediate dataframe
        # apply a lambda function to check if the "Gene Name" is in the bionda_values list, if yes, set the value to 1, else, set the value to 0
        intermediate_df["BIONDA_Marker"] = intermediate_df["Gene Name"].apply(lambda x: 1 if x in bionda_values else 0)
    else:
        intermediate_df["BIONDA_Marker"] = "#N/A"

    # create a list of column names to apply the formulas on
    columns_to_apply_formulas_on = ['MOD_DISGENET_Score', 'Mod_Standard_Value', 'Mod_Pubpular', 'Mod_CTD']

    # calculate the new columns for all possible pairs of columns in the list using the formulas
    for i in range(len(columns_to_apply_formulas_on)):
        if columns_to_apply_formulas_on[i] not in intermediate_df.columns:
            intermediate_df[columns_to_apply_formulas_on[i]] = 0
            continue
        for j in range(i+1, len(columns_to_apply_formulas_on)):
            if columns_to_apply_formulas_on[j] not in intermediate_df.columns:
                intermediate_df[columns_to_apply_formulas_on[j]] = 0
                continue
            # create a new column name by concatenating the two column names with "top_" in the beginning
            colname = 'top_' + columns_to_apply_formulas_on[i].lower() + '_' + columns_to_apply_formulas_on[j].lower()
            # apply the formula to calculate the value for each row in the new column
            intermediate_df[colname] = ((intermediate_df[[columns_to_apply_formulas_on[i], columns_to_apply_formulas_on[j]]].mean(axis=1)) +
                            (1 - (intermediate_df[[columns_to_apply_formulas_on[i], columns_to_apply_formulas_on[j]]].std(axis=1) /
                                    intermediate_df[[columns_to_apply_formulas_on[i], columns_to_apply_formulas_on[j]]].mean(axis=1))) / 2)


    
    #dis2_df = pd.read_csv("/filepath")
    #dis2_names = list(dis2_df['Name'])

    #intermediate_df['Dis_2_Marker'] = intermediate_df['Gene Name'].apply(lambda x: 1 if x in dis2_names else 0)

    intermediate_df = intermediate_df.assign(Dis_2_Marker = 0)

    
    intermediate_df = intermediate_df.loc[:, ['SwissProt Accessions', 'Gene Name', 'MOD_DISGENET_Score', 'Mod_Standard_Value', 'Mod_Pubpular', 'Mod_CTD', 'top_mod_disgenet_score_mod_standard_value', 'top_mod_disgenet_score_mod_pubpular', 'top_mod_disgenet_score_mod_ctd', 'top_mod_standard_value_mod_pubpular', 'top_mod_standard_value_mod_ctd', 'top_mod_pubpular_mod_ctd', 'CTD_Marker', 'Edager_Marker', 'BIONDA_Marker', 'Dis_2_Marker']]


    intermediate_df = intermediate_df.rename(columns={
    'top_mod_disgenet_score_mod_standard_value': 'D_H',
    'top_mod_disgenet_score_mod_pubpular': 'D_P',
    'top_mod_disgenet_score_mod_ctd': 'D_C',
    'top_mod_standard_value_mod_pubpular': 'H_P',
    'top_mod_standard_value_mod_ctd': 'H_C',
    'top_mod_pubpular_mod_ctd': 'P_C'
    })

    

    intermediate_df.dropna(subset=['Gene Name', 'SwissProt Accessions'], how='all', inplace=True)

    # create a master file path by joining the master folder path, disease name, and MESH ID
    master_file_path = os.path.join(master_folder_path, f"BDMC_Final_{Disease_Name}_{MESH_ID}.csv")

    # write the intermediate dataframe to a csv file with the master file path
    # set the index to False to not include the index column in the output csv file
    intermediate_df.to_csv(master_file_path, index=False)
    # print a success message with the disease name
    print(f"Successfully Downloaded Master Data for {Disease_Name}")
